{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrcwIG63NO7BJ/2ZaJfV96",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julmiha25-sys/Python/blob/main/%D0%9A%D0%B5%D0%B9%D1%811.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, glob, sys, csv # –†–∞–±–æ—Ç–∞ —Å –û–°, —Ä–µ–≥—É–ª. –≤—ã—Ä–∞–∂., –ø–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤, —Å–∏—Å—Ç. –ø–∞—Ä-–º–∏, csv-—Ñ–∞–π–ª–∞–º–∏\n",
        "\n",
        "def process_files(src_folder, dest_folder):\n",
        "    current_dir = os.getcwd() # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –æ—Ç–Ω–æ—Å. –ø—É—Ç–µ–π –≤ –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ\n",
        "    if not os.path.isabs(src_folder):\n",
        "        src_folder = os.path.join(current_dir, src_folder)\n",
        "    if not os.path.isabs(dest_folder):\n",
        "        dest_folder = os.path.join(current_dir, dest_folder)\n",
        "    os.makedirs(dest_folder, exist_ok=True) # –ï—Å–ª–∏ –ø–∞–ø–∫–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –Ω–µ—Ç, —Ç–æ —Å–æ–∑–¥–∞–µ–º –µ–µ\n",
        "\n",
        "    sys.path.append(os.path.join(os.getcwd(), '..', src_folder))\n",
        "    if not os.path.exists(src_folder) or not os.path.exists(dest_folder):\n",
        "        print(f\"‚ùå –ü–∞–ø–∫–∏ '{src_folder}' –∏–ª–∏ '{dest_folder}' –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç\")\n",
        "        return None\n",
        "\n",
        "    filter_files = r'\\d{4}-\\d{2}-\\d{2}-\\d{2}-\\d{2}-\\d+\\.csv' # –®–∞–±–ª–æ–Ω —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π\n",
        "    files_cvs = glob.glob(os.path.join(src_folder, '*.csv')) # –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ –ø–æ —à–∞–±–ª–æ–Ω—É\n",
        "    files = [f for f in files_cvs if re.match(filter_files, os.path.basename(f))] # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ csv\n",
        "\n",
        "    if not files_cvs:\n",
        "        print(f\"‚ùå –í –ø–∞–ø–∫–µ '{src_folder}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ CSV —Ñ–∞–π–ª–æ–≤\")\n",
        "        return None\n",
        "\n",
        "    if len(files_cvs) > len(files):\n",
        "        print(f\"‚ùå –í –ø–∞–ø–∫–µ '{src_folder}' –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç CSV —Ñ–∞–π–ª—ã, –Ω–æ –Ω–µ –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.\")\n",
        "        print(f\"    –û–∂–∏–¥–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: –ì–ì–ì–ì-–ú–ú-–î–î-–ß–ß-–ú–ú-id–º–∞–≥–∞–∑–∏–Ω–∞.csv \\n\")\n",
        "        if not files:\n",
        "            return None\n",
        "\n",
        "    print(f\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ –∫–æ–ª-–≤–µ {len(files)}:\")\n",
        "    for f in files:\n",
        "        print(f\" - {os.path.basename(f)}\")\n",
        "\n",
        "    output_file = os.path.join(dest_folder, 'combined_data.csv')\n",
        "\n",
        "    print(f\"\\nüìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤:\")\n",
        "    all_headers_sets = [] # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –Ω–∞–±–æ—Ä–æ–≤ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤\n",
        "    headers_info = {} # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞\n",
        "    skipped_files_pre = [] # –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã\n",
        "\n",
        "    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è –≤ CSV —Ñ–∞–π–ª–µ\n",
        "    def detect_delimiter(file_path, encoding='utf-8', sample_lines=5):\n",
        "        delimiters = [',', ';', '\\t', '|'] # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è –≤ CSV –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º —Å—Ç—Ä–æ–∫–∞–º\n",
        "        delimiter_counts = {d: 0 for d in delimiters}\n",
        "\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding=encoding) as f:\n",
        "                lines_read = 0\n",
        "                for line in f:\n",
        "                    if lines_read >= sample_lines: # –ß—Ç–µ–Ω–∏–µ –ø–µ—Ä–≤—ã—Ö –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å—Ç—Ä–æ–∫\n",
        "                        break\n",
        "\n",
        "                    for delimiter in delimiters:\n",
        "                        delimiter_counts[delimiter] += line.count(delimiter) # –ü–æ–∏—Å–∫ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è —Å –º–∞–∫—Å —á–∏—Å–ª–æ–º –≤—Ö–æ–∂–¥–µ–Ω–∏–π\n",
        "\n",
        "                    lines_read += 1\n",
        "\n",
        "            best_delimiter = max(delimiter_counts, key=delimiter_counts.get) # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –≤—Ö–æ–∂–¥–µ–Ω–∏–π\n",
        "\n",
        "            if delimiter_counts[best_delimiter] == 0:  # , - –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n",
        "                return ','\n",
        "\n",
        "            return best_delimiter\n",
        "        except:\n",
        "            return ','  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n",
        "\n",
        "    for idx, file_path in enumerate(files):\n",
        "        file_name = os.path.basename(file_path)\n",
        "        headers_found = False\n",
        "\n",
        "        for encoding in ['utf-8', 'cp1251']: # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ä–∞–±–æ—Ç–∞–µ–º —Å 2-—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞–º–∏\n",
        "            try:\n",
        "                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –¥–ª—è —Ñ–∞–π–ª–∞\n",
        "                delimiter = detect_delimiter(file_path, encoding)\n",
        "\n",
        "                with open(file_path, 'r', encoding=encoding) as f:\n",
        "                    reader = csv.reader(f, delimiter=delimiter, quotechar='\"') # –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –¥–ª—è –ø–æ—Å—Ç—Ä–æ—á–Ω–æ–≥–æ —á—Ç–µ–Ω–∏—è csv-—Ñ–∞–π–ª–∞ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º\n",
        "                    current_headers = next(reader) # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞\n",
        "\n",
        "                    try: # –ß–∏—Ç–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∞–π–ª–∞ –Ω–∞ –ø—É—Å—Ç–æ—Ç—É\n",
        "                        first_data_row = next(reader) # –ü–æ–ª—É—á–µ–Ω–∏–µ 1-–π —Å—Ç—Ä–æ–∫–∏ –ø–æ—Å–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞\n",
        "                        f.seek(0) # –í–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ –∫ –Ω–∞—á–∞–ª—É —Ñ–∞–π–ª–∞\n",
        "                        next(reader) # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å–Ω–æ–≤–∞\n",
        "\n",
        "                    except StopIteration:\n",
        "                        skipped_files_pre.append((idx + 1, file_name, \"–§–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫\"))\n",
        "                        break\n",
        "\n",
        "                    headers_found = True\n",
        "                    headers_set = set(current_headers)\n",
        "                    all_headers_sets.append(headers_set)\n",
        "                    headers_info[file_name] = {\n",
        "                        'path': file_path,\n",
        "                        'headers': current_headers,\n",
        "                        'headers_set': headers_set,\n",
        "                        'encoding': encoding,\n",
        "                        'delimiter': delimiter  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å\n",
        "                    }\n",
        "                    print(f\"  {idx + 1}. üìÑ {file_name} - {len(current_headers)} –∫–æ–ª–æ–Ω–æ–∫ (—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: '{delimiter}')\")\n",
        "                    break\n",
        "\n",
        "            except StopIteration: # –ï—Å–ª–∏ —Ñ–∞–π–ª –ø—É—Å—Ç–æ–π\n",
        "                skipped_files_pre.append((idx + 1, file_name, \"–§–∞–π–ª –ø—É—Å—Ç–æ–π\"))\n",
        "                break\n",
        "            except UnicodeDecodeError: # –ï—Å–ª–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∞ –Ω–µ utf-8 –∏ –Ω–µ cp1251\n",
        "                continue\n",
        "            except Exception as e:  # –ü—Ä–æ—á–∏–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è\n",
        "                skipped_files_pre.append((idx + 1, file_name, f\"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è: {str(e)[:50]}\"))\n",
        "                break\n",
        "\n",
        "        if not headers_found and file_name not in [f[1] for f in skipped_files_pre]:\n",
        "            skipped_files_pre.append((idx + 1, file_name, \"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∏\"))\n",
        "\n",
        "    # –ü–æ–∏—Å–∫ –æ–±—â–∏—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
        "    if not all_headers_sets:\n",
        "        print(\"\\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∏ –Ω–∏ –∏–∑ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞\")\n",
        "        for num, fname, reason in skipped_files_pre:\n",
        "            print(f\"  {num}. ‚≠ï {fname} - {reason}\")\n",
        "        return None\n",
        "\n",
        "    common_headers = set.intersection(*all_headers_sets) if len(all_headers_sets) > 1 else all_headers_sets[0] # –û–±—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏\n",
        "\n",
        "    if not common_headers:\n",
        "        print(\"‚ö†Ô∏è  –ù–µ—Ç –∫–æ–ª–æ–Ω–æ–∫, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤–æ –≤—Å–µ—Ö —Ñ–∞–π–ª–∞—Ö\")\n",
        "\n",
        "        column_frequency = {}\n",
        "        for headers_set in all_headers_sets:\n",
        "            for header in headers_set:\n",
        "                column_frequency[header] = column_frequency.get(header, 0) + 1 # –ß–∞—Å—Ç–æ—Ç–∞ –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç–∏ –∫–æ–ª–æ–Ω–æ–∫\n",
        "        min_files = max(2, len(files) // 2)  # –ú–∏–Ω–∏–º—É–º 2 —Ñ–∞–π–ª–∞ –∏–ª–∏ 50% –æ—Ç –∫–æ–ª-–≤–∞ –∫–æ–ª–æ–Ω–æ–∫ —Å–æ–≤–ø–∞–¥–∞—é—Ç\n",
        "        common_headers = {header for header, count in column_frequency.items()\n",
        "                         if count >= min_files}\n",
        "        print(f\"   –í—ã–±—Ä–∞–Ω—ã –∫–æ–ª–æ–Ω–∫–∏, –∏–º–µ—é—â–∏–µ—Å—è —Ö–æ—Ç—è –±—ã –≤ {min_files} —Ñ–∞–π–ª–∞—Ö\")\n",
        "\n",
        "    if not common_headers:\n",
        "        print(\"\\n‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –æ–±—â–∏—Ö –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏\")\n",
        "        print(\"   –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º:\")\n",
        "        column_frequency = {}\n",
        "        for headers_set in all_headers_sets:\n",
        "            for header in headers_set:\n",
        "                column_frequency[header] = column_frequency.get(header, 0) + 1\n",
        "        for header, count in sorted(column_frequency.items(), key=lambda x: (-x[1], x[0])):\n",
        "            print(f\"   - '{header}': {count} —Ñ–∞–π–ª(–æ–≤)\")\n",
        "        return None\n",
        "\n",
        "    target_headers = []\n",
        "    for file_name, info in headers_info.items(): # –ü–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ —Ñ–∞–π–ª–∞, —É –∫–æ—Ç–æ—Ä–æ–≥–æ –µ—Å—Ç—å –≤—Å–µ –æ–±—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏\n",
        "        if common_headers.issubset(info['headers_set']):\n",
        "            target_headers = [h for h in info['headers'] if h in common_headers]\n",
        "            break\n",
        "\n",
        "    if not target_headers: # –ò–ª–∏ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫\n",
        "        target_headers = sorted(list(common_headers))\n",
        "\n",
        "    print(f\"\\nüéØ –û–±—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ ({len(target_headers)}): {', '.join(target_headers)}\")\n",
        "\n",
        "    # –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ >=50% –æ–±—â–∏—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
        "    processable_files = []\n",
        "    unprocessable_files = []\n",
        "\n",
        "    for file_name, info in headers_info.items():\n",
        "        common_with_file = common_headers.intersection(info['headers_set'])\n",
        "        common_count = len(common_with_file)\n",
        "        total_common = len(common_headers)\n",
        "\n",
        "        if common_count >= total_common * 0.5:  # –ï—Å—Ç—å 50% –æ–±—â–∏—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
        "            processable_files.append(file_name)\n",
        "            print(f\"   ‚úÖ {file_name}: {common_count}/{total_common} –æ–±—â–∏—Ö –∫–æ–ª–æ–Ω–æ–∫\")\n",
        "        else:\n",
        "            unprocessable_files.append((file_name, f\"–°–æ–≤–ø–∞–¥–∞–µ—Ç —Ç–æ–ª—å–∫–æ {common_count} –∏–∑ {total_common} –∫–æ–ª–æ–Ω–æ–∫\"))\n",
        "            print(f\"   ‚ùå {file_name}: —Ç–æ–ª—å–∫–æ {common_count}/{total_common} –æ–±—â–∏—Ö –∫–æ–ª–æ–Ω–æ–∫\")\n",
        "\n",
        "    if not processable_files:\n",
        "        print(\"\\n‚ùå –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ —Å –ø–æ–¥—Ö–æ–¥—è—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏\")\n",
        "        return None\n",
        "\n",
        "    # –í–°–ï–ì–î–ê –ò–°–ü–û–õ–¨–ó–£–ï–ú –ó–ê–ü–Ø–¢–£–Æ –ö–ê–ö –†–ê–ó–î–ï–õ–ò–¢–ï–õ–¨ –î–õ–Ø –í–´–•–û–î–ù–û–ì–û –§–ê–ô–õ–ê\n",
        "    output_delimiter = ','  # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —ç—Ç–∞–ª–æ–Ω–æ–º\n",
        "    print(f\"\\nüîß –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –¥–ª—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: '{output_delimiter}' (—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)\")\n",
        "\n",
        "    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ñ–∞–π–ª–æ–≤\n",
        "    all_rows = [] # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å—Ç—Ä–æ–∫ csv-—Ñ–∞–π–ª–æ–≤\n",
        "    total_rows = 0  # –°—á–µ—Ç—á–∏–∫ –∫–æ–ª-–≤–∞ —Å—Ç—Ä–æ–∫ –∏–∑ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤\n",
        "    processed_files = 0  # –°—á–µ—Ç—á–∏–∫ –∫–æ–ª-–≤–∞ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤\n",
        "    skipped_files = []  # –°–ø–∏—Å–æ–∫ —Å –∫–æ—Ä—Ç–µ–∂–∞–º–∏ —Å –∏–Ω—Ñ-–µ–π –æ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö\n",
        "\n",
        "    print(f\"\\nüîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ ({len(processable_files)} –∏–∑ {len(files)}):\")\n",
        "\n",
        "    for idx, file_name in enumerate(processable_files, 1):\n",
        "        info = headers_info[file_name]\n",
        "        file_path = info['path']\n",
        "        current_headers = info['headers']\n",
        "        encoding = info['encoding']\n",
        "        delimiter = info['delimiter']\n",
        "\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding=encoding) as f:\n",
        "                reader = csv.reader(f, delimiter=delimiter, quotechar='\"') # –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –¥–ª—è –ø–æ—Å—Ç—Ä–æ—á–Ω–æ–≥–æ —á—Ç–µ–Ω–∏—è csv-—Ñ–∞–π–ª–∞\n",
        "                next(reader) # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ (—É–∂–µ –ø—Ä–æ—á–∏—Ç–∞–Ω)\n",
        "\n",
        "                file_rows = []\n",
        "                for row in reader: # –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
        "                    file_rows.append(row)\n",
        "\n",
        "                if len(file_rows) == 0:\n",
        "                    print(f\"  {idx}. ‚≠ï {file_name} - –§–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏\")\n",
        "                    skipped_files.append((idx, file_name, \"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö\"))\n",
        "                    continue\n",
        "\n",
        "                aligned_rows = [] # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —Å—Ç—Ä–æ–∫ –ø–æ–¥ –æ–±—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏\n",
        "\n",
        "                header_to_idx = {header: i for i, header in enumerate(current_headers)} # –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ –∏ –∏–Ω–¥–µ–∫—Å–∞–º–∏\n",
        "\n",
        "                for row in file_rows:\n",
        "                    aligned_row = []\n",
        "                    for target_header in target_headers:\n",
        "                        if target_header in header_to_idx:\n",
        "                            idx_in_file = header_to_idx[target_header]\n",
        "                            if idx_in_file < len(row):\n",
        "                                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –∫–∞–∫ –µ—Å—Ç—å, –±–µ–∑ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤ '0'\n",
        "                                aligned_row.append(row[idx_in_file])\n",
        "                            else:\n",
        "                                aligned_row.append('')  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –≤–º–µ—Å—Ç–æ '0'\n",
        "                        else:\n",
        "                            aligned_row.append('')  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –≤–º–µ—Å—Ç–æ '0'\n",
        "                    aligned_rows.append(aligned_row)\n",
        "\n",
        "                all_rows.extend(aligned_rows) # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—Ä–æ–≤–Ω–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏\n",
        "                total_rows += len(file_rows) # –ù–∞—Ä–∞—â–∏–≤–∞–Ω–∏–µ –æ–±—â–µ–≥–æ –∫–æ–ª-–≤–∞ —Å—Ç—Ä–æ–∫\n",
        "                processed_files += 1 # –ù–∞—Ä–∞—â–∏–≤–∞–Ω–∏–µ –∫–æ–ª-–≤–∞ –æ–±—Ä–∞–±. —Ñ–∞–π–ª–æ–≤\n",
        "                print(f\"  {idx}. ‚òëÔ∏è {file_name} - {len(file_rows):,} —Å—Ç—Ä–æ–∫\")\n",
        "\n",
        "        except Exception as e:  # –ü—Ä–æ—á–∏–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è\n",
        "            print(f\"  {idx}. ‚≠ï {file_name} - –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)[:50]}\")\n",
        "            skipped_files.append((idx, file_name, f\"–û—à–∏–±–∫–∞: {str(e)[:50]}\"))\n",
        "\n",
        "    if skipped_files_pre or unprocessable_files:\n",
        "        print(f\"\\nüìã –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:\")\n",
        "\n",
        "        for num, fname, reason in skipped_files_pre:\n",
        "            print(f\"  {num}. ‚≠ï {fname} - {reason}\")\n",
        "\n",
        "        for fname, reason in unprocessable_files:\n",
        "            for orig_idx, orig_file in enumerate(files, 1): # –ü–æ–∏—Å–∫ ‚Ññ —Ñ–∞–π–ª–∞\n",
        "                if os.path.basename(orig_file) == fname:\n",
        "                    print(f\"  {orig_idx}. ‚≠ï {fname} - {reason}\")\n",
        "                    break\n",
        "\n",
        "    if not all_rows: # –ù–∏ –æ–¥–∏–Ω —Ñ–∞–π–ª –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å\n",
        "        print(\"\\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ñ–∞–π–ª–æ–≤\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        date_index = None\n",
        "        for i, header in enumerate(target_headers): # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å –∫–æ–ª–æ–Ω–∫–∏ date –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏\n",
        "            if header.lower() == 'date':\n",
        "                date_index = i\n",
        "                break\n",
        "\n",
        "        if date_index is not None:\n",
        "            print(f\"\\nüîÉ –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫–∏ –ø–æ –¥–∞—Ç–µ (–∫–æ–ª–æ–Ω–∫–∞ '{target_headers[date_index]}')...\")\n",
        "\n",
        "            def parse_date(date_str):  # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏\n",
        "                try:\n",
        "                    year, month, day = map(int, date_str.split('-'))\n",
        "                    return (year, month, day)\n",
        "                except:\n",
        "                    return (9999, 12, 31)\n",
        "\n",
        "            all_rows.sort(key=lambda row: parse_date(row[date_index] if len(row) > date_index else '')) # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Å—Ç—Ä–æ–∫ –ø–æ –¥–∞—Ç–µ\n",
        "\n",
        "            if all_rows: # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏\n",
        "                print(f\"   –ü–µ—Ä–≤–∞—è –¥–∞—Ç–∞ –ø–æ—Å–ª–µ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏: {all_rows[0][date_index] if len(all_rows[0]) > date_index else 'N/A'}\")\n",
        "                print(f\"   –ü–æ—Å–ª–µ–¥–Ω—è—è –¥–∞—Ç–∞ –ø–æ—Å–ª–µ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏: {all_rows[-1][date_index] if len(all_rows[-1]) > date_index else 'N/A'}\")\n",
        "        else:\n",
        "            print(f\"\\n‚ö†Ô∏è  –ö–æ–ª–æ–Ω–∫–∞ 'date' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –æ–±—â–∏—Ö –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö. –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–µ: {e}\")\n",
        "\n",
        "    output_file = os.path.join(dest_folder, 'combined_data.csv')\n",
        "\n",
        "    try:\n",
        "\n",
        "        with open(output_file, 'w', encoding='utf-8', newline='') as f:\n",
        "            writer = csv.writer(f, delimiter=output_delimiter, quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "            writer.writerow(target_headers)\n",
        "            writer.writerows(all_rows)\n",
        "\n",
        "        print(f\"\\n‚úÖ CSV —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {output_file}\")\n",
        "        print(f\" - –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {total_rows}\")\n",
        "        print(f\" - –§–∞–π–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_files} –∏–∑ {len(processable_files)} –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö\")\n",
        "        print(f\" - –§–∞–π–ª–æ–≤ –ø—Ä–æ–ø—É—â–µ–Ω–æ: {len(files) - processed_files}\")\n",
        "        print(f\" - –ö–æ–ª–æ–Ω–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {len(target_headers)}\")\n",
        "        if unprocessable_files:\n",
        "            print(f\" - –§–∞–π–ª–æ–≤ —Å –Ω–µ–ø–æ–¥—Ö–æ–¥—è—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π: {len(unprocessable_files)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}\")\n",
        "        return None\n",
        "\n",
        "process_files('Input', 'Output')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZazooJ8xNNn",
        "outputId": "9a86725c-9d76-4e97-d090-14fb1b5cc1b6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùå –í –ø–∞–ø–∫–µ '/content/Input' –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç CSV —Ñ–∞–π–ª—ã, –Ω–æ –Ω–µ –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.\n",
            "    –û–∂–∏–¥–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: –ì–ì–ì–ì-–ú–ú-–î–î-–ß–ß-–ú–ú-id–º–∞–≥–∞–∑–∏–Ω–∞.csv \n",
            "\n",
            "‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ –∫–æ–ª-–≤–µ 5:\n",
            " - 2025-02-05-12-40-8.csv\n",
            " - 2025-02-01-13-40-10.csv\n",
            " - 2025-01-02-12-30-5.csv\n",
            " - 2025-02-03-05-30-5.csv\n",
            " - 2025-05-02-15-30-9.csv\n",
            "\n",
            "üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤:\n",
            "  1. üìÑ 2025-02-05-12-40-8.csv - 4 –∫–æ–ª–æ–Ω–æ–∫ (—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: ',')\n",
            "  2. üìÑ 2025-02-01-13-40-10.csv - 2 –∫–æ–ª–æ–Ω–æ–∫ (—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: ',')\n",
            "  3. üìÑ 2025-01-02-12-30-5.csv - 2 –∫–æ–ª–æ–Ω–æ–∫ (—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: ',')\n",
            "  4. üìÑ 2025-02-03-05-30-5.csv - 1 –∫–æ–ª–æ–Ω–æ–∫ (—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: ',')\n",
            "  5. üìÑ 2025-05-02-15-30-9.csv - 3 –∫–æ–ª–æ–Ω–æ–∫ (—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: ',')\n",
            "‚ö†Ô∏è  –ù–µ—Ç –∫–æ–ª–æ–Ω–æ–∫, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤–æ –≤—Å–µ—Ö —Ñ–∞–π–ª–∞—Ö\n",
            "   –í—ã–±—Ä–∞–Ω—ã –∫–æ–ª–æ–Ω–∫–∏, –∏–º–µ—é—â–∏–µ—Å—è —Ö–æ—Ç—è –±—ã –≤ 2 —Ñ–∞–π–ª–∞—Ö\n",
            "\n",
            "üéØ –û–±—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ (3): \u0000T\u0000h\u0000e\u0000r\u0000a\u0000p\u0000y\u0000, expr, —é—è\u0000e\u0000x\u0000p\u0000r\u0000\n",
            "   ‚ùå 2025-02-05-12-40-8.csv: —Ç–æ–ª—å–∫–æ 0/3 –æ–±—â–∏—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
            "   ‚úÖ 2025-02-01-13-40-10.csv: 2/3 –æ–±—â–∏—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
            "   ‚ùå 2025-01-02-12-30-5.csv: —Ç–æ–ª—å–∫–æ 1/3 –æ–±—â–∏—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
            "   ‚ùå 2025-02-03-05-30-5.csv: —Ç–æ–ª—å–∫–æ 1/3 –æ–±—â–∏—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
            "   ‚úÖ 2025-05-02-15-30-9.csv: 2/3 –æ–±—â–∏—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
            "\n",
            "üîß –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –¥–ª—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: ',' (—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)\n",
            "\n",
            "üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ (2 –∏–∑ 5):\n",
            "  1. ‚òëÔ∏è 2025-02-01-13-40-10.csv - 121 —Å—Ç—Ä–æ–∫\n",
            "  2. ‚òëÔ∏è 2025-05-02-15-30-9.csv - 121 —Å—Ç—Ä–æ–∫\n",
            "\n",
            "üìã –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:\n",
            "  1. ‚≠ï 2025-02-05-12-40-8.csv - –°–æ–≤–ø–∞–¥–∞–µ—Ç —Ç–æ–ª—å–∫–æ 0 –∏–∑ 3 –∫–æ–ª–æ–Ω–æ–∫\n",
            "  3. ‚≠ï 2025-01-02-12-30-5.csv - –°–æ–≤–ø–∞–¥–∞–µ—Ç —Ç–æ–ª—å–∫–æ 1 –∏–∑ 3 –∫–æ–ª–æ–Ω–æ–∫\n",
            "  4. ‚≠ï 2025-02-03-05-30-5.csv - –°–æ–≤–ø–∞–¥–∞–µ—Ç —Ç–æ–ª—å–∫–æ 1 –∏–∑ 3 –∫–æ–ª–æ–Ω–æ–∫\n",
            "\n",
            "‚ö†Ô∏è  –ö–æ–ª–æ–Ω–∫–∞ 'date' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –æ–±—â–∏—Ö –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö. –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞.\n",
            "\n",
            "‚úÖ CSV —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: /content/Output/combined_data.csv\n",
            " - –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: 242\n",
            " - –§–∞–π–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 2 –∏–∑ 2 –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö\n",
            " - –§–∞–π–ª–æ–≤ –ø—Ä–æ–ø—É—â–µ–Ω–æ: 3\n",
            " - –ö–æ–ª–æ–Ω–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: 3\n",
            " - –§–∞–π–ª–æ–≤ —Å –Ω–µ–ø–æ–¥—Ö–æ–¥—è—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IEJTVqdI0Wrk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vJyGVS0Zi1Q1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# –ù–æ–≤—ã–π —Ä–∞–∑–¥–µ–ª"
      ],
      "metadata": {
        "id": "yLaOwqni0UmQ"
      }
    }
  ]
}
